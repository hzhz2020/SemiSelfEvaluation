{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be582a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d0321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/cluster/tufts/hugheslab/zhuang12/SemiSelfEvaluationProject/ML_DATA/MedMNIST/TissueMNIST/unnormalized_HWC/data_seed0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5277ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_means_and_std(images):\n",
    "\n",
    "#     means = 0\n",
    "#     stds = 0\n",
    "\n",
    "#     assert images.ndim == 3 #data['images'] N, H, W\n",
    "#     for image in images:\n",
    "#         means += image.mean()\n",
    "#         stds += image.std()\n",
    "\n",
    "#     means = means/len(images)\n",
    "#     stds = stds/len(images)\n",
    "\n",
    "#     print('means: {}'.format(means))\n",
    "#     print('stds: {}'.format(stds))\n",
    "    \n",
    "#     return means, stds\n",
    "def get_means_and_std(images):\n",
    "\n",
    "    means = np.zeros(3)\n",
    "    stds = np.zeros(3)\n",
    "\n",
    "    assert images.shape[3] == 3 #data['images'] N, H, W, C\n",
    "    for image in images:\n",
    "\n",
    "        for i in range(3):\n",
    "            means[i] += image[:,:,i].mean()\n",
    "            stds[i] += image[:,:,i].std()\n",
    "\n",
    "    means = means/len(images)\n",
    "    stds = stds/len(images)\n",
    "\n",
    "    print('means: {}'.format(means))\n",
    "    print('stds: {}'.format(stds))\n",
    "    \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbee5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "026f11e1",
   "metadata": {},
   "source": [
    "### Load data from 400/ 23,640/ 47,280/ 165,066 (train/val/test/unlabeled) split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575179d5",
   "metadata": {},
   "source": [
    "### nlabels400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1df1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_train_path = os.path.join(root_dir, 'nlabels400', 'l_train.npy')\n",
    "# u_train_path = os.path.join(root_dir, 'nlabels400', 'u_train.npy')\n",
    "val_path = os.path.join(root_dir, 'nlabels400', 'val.npy')\n",
    "# test_path = os.path.join(root_dir, 'nlabels400', 'test.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c569d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_train = np.load(l_train_path, allow_pickle=True).item()\n",
    "# u_train = np.load(u_train_path, allow_pickle=True).item()\n",
    "val = np.load(val_path, allow_pickle=True).item()\n",
    "# test = np.load(test_path, allow_pickle=True).item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf0771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94b9ca33",
   "metadata": {},
   "source": [
    "#### val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d75f157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23640, 28, 28, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0772ff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples each class\n",
      "0: 7582\n",
      "1: 1117\n",
      "2: 838\n",
      "3: 2201\n",
      "4: 1684\n",
      "5: 1101\n",
      "6: 5601\n",
      "7: 3516\n"
     ]
    }
   ],
   "source": [
    "N_class0 = np.sum(val['labels']==0)\n",
    "N_class1 = np.sum(val['labels']==1)\n",
    "N_class2 = np.sum(val['labels']==2)\n",
    "N_class3 = np.sum(val['labels']==3)\n",
    "N_class4 = np.sum(val['labels']==4)\n",
    "N_class5 = np.sum(val['labels']==5)\n",
    "N_class6 = np.sum(val['labels']==6)\n",
    "N_class7 = np.sum(val['labels']==7)\n",
    "\n",
    "print('num samples each class')\n",
    "print('0: {}\\n1: {}\\n2: {}\\n3: {}\\n4: {}\\n5: {}\\n6: {}\\n7: {}'.format(N_class0, N_class1, N_class2, N_class3, N_class4, N_class5, N_class6, N_class7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03fa48b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means: [26.02644266 26.02644266 26.02644266]\n",
      "stds: [20.3406241 20.3406241 20.3406241]\n"
     ]
    }
   ],
   "source": [
    "val_means, val_stds = get_means_and_std(val['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a461b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_class0_ratio: 0.3207275803722504\n",
      "val_class1_ratio: 0.04725042301184433\n",
      "val_class2_ratio: 0.03544839255499154\n",
      "val_class3_ratio: 0.09310490693739425\n",
      "val_class4_ratio: 0.07123519458544839\n",
      "val_class5_ratio: 0.0465736040609137\n",
      "val_class6_ratio: 0.23692893401015228\n",
      "val_class7_ratio: 0.14873096446700507\n"
     ]
    }
   ],
   "source": [
    "val_class0_ratio = N_class0/val['images'].shape[0]\n",
    "val_class1_ratio = N_class1/val['images'].shape[0]\n",
    "val_class2_ratio = N_class2/val['images'].shape[0]\n",
    "val_class3_ratio = N_class3/val['images'].shape[0]\n",
    "val_class4_ratio = N_class4/val['images'].shape[0]\n",
    "val_class5_ratio = N_class5/val['images'].shape[0]\n",
    "val_class6_ratio = N_class6/val['images'].shape[0]\n",
    "val_class7_ratio = N_class7/val['images'].shape[0]\n",
    "\n",
    "print('val_class0_ratio: {}'.format(val_class0_ratio))\n",
    "print('val_class1_ratio: {}'.format(val_class1_ratio))\n",
    "print('val_class2_ratio: {}'.format(val_class2_ratio))\n",
    "print('val_class3_ratio: {}'.format(val_class3_ratio))\n",
    "print('val_class4_ratio: {}'.format(val_class4_ratio))\n",
    "print('val_class5_ratio: {}'.format(val_class5_ratio))\n",
    "print('val_class6_ratio: {}'.format(val_class6_ratio))\n",
    "print('val_class7_ratio: {}'.format(val_class7_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8188452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_class0_400valsplit: 128\n",
      "N_class1_400valsplit: 19\n",
      "N_class2_400valsplit: 14\n",
      "N_class3_400valsplit: 37\n",
      "N_class4_400valsplit: 28\n",
      "N_class5_400valsplit: 19\n",
      "N_class6_400valsplit: 95\n",
      "N_class7_400valsplit: 59\n"
     ]
    }
   ],
   "source": [
    "N_class0_400valsplit = round(val_class0_ratio * 400)\n",
    "N_class1_400valsplit = round(val_class1_ratio * 400)\n",
    "N_class2_400valsplit = round(val_class2_ratio * 400)\n",
    "N_class3_400valsplit = round(val_class3_ratio * 400)\n",
    "N_class4_400valsplit = round(val_class4_ratio * 400)\n",
    "N_class5_400valsplit = round(val_class5_ratio * 400)\n",
    "N_class6_400valsplit = round(val_class6_ratio * 400)\n",
    "N_class7_400valsplit = round(val_class7_ratio * 400)\n",
    "\n",
    "print('N_class0_400valsplit: {}'.format(N_class0_400valsplit))\n",
    "print('N_class1_400valsplit: {}'.format(N_class1_400valsplit))\n",
    "print('N_class2_400valsplit: {}'.format(N_class2_400valsplit))\n",
    "print('N_class3_400valsplit: {}'.format(N_class3_400valsplit))\n",
    "print('N_class4_400valsplit: {}'.format(N_class4_400valsplit))\n",
    "print('N_class5_400valsplit: {}'.format(N_class5_400valsplit))\n",
    "print('N_class6_400valsplit: {}'.format(N_class6_400valsplit))\n",
    "print('N_class7_400valsplit: {}'.format(N_class7_400valsplit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bf2503b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_class0_400valsplit+N_class1_400valsplit+N_class2_400valsplit+N_class3_400valsplit+N_class4_400valsplit+N_class5_400valsplit+N_class6_400valsplit+N_class7_400valsplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c38850",
   "metadata": {},
   "source": [
    "#### final plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "278982ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_N_class0_400valsplit = 128\n",
    "choose_N_class1_400valsplit = 19\n",
    "choose_N_class2_400valsplit = 15 #add 1 to 14, so that total is 400\n",
    "choose_N_class3_400valsplit = 37\n",
    "choose_N_class4_400valsplit = 28\n",
    "choose_N_class5_400valsplit = 19\n",
    "choose_N_class6_400valsplit = 95\n",
    "choose_N_class7_400valsplit = 59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df226c7c",
   "metadata": {},
   "source": [
    "#### From the original val set of the 400/ 23,640/ 47,280/ 165,066 (train/val/test/unlabeled) split, choose 400 samples in the val set according to choose_N_classX_400valsplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076c50f",
   "metadata": {},
   "source": [
    "#### directly copy over the l_train.npy, test.npy and u_train.npy fron nlabels400/ to nlabels400_val400/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a57e50f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permuted indices: [21714  5075 12283 ...  9845 10799  2732]\n",
      "saintycheck, class 0 has 7582 samples, to choose 128\n",
      "saintycheck, class 1 has 1117 samples, to choose 19\n",
      "saintycheck, class 2 has 838 samples, to choose 15\n",
      "saintycheck, class 3 has 2201 samples, to choose 37\n",
      "saintycheck, class 4 has 1684 samples, to choose 28\n",
      "saintycheck, class 5 has 1101 samples, to choose 19\n",
      "saintycheck, class 6 has 5601 samples, to choose 95\n",
      "saintycheck, class 7 has 3516 samples, to choose 59\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "indices = rng.permutation(len(val['images']))\n",
    "print('permuted indices: {}'.format(indices))\n",
    "\n",
    "permuted_val_images = val['images'][indices]\n",
    "permuted_val_labels = val['labels'][indices]\n",
    "\n",
    "new_400valsplit_images = []\n",
    "new_400valsplit_labels = []\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "samples_to_choose_each_class = [choose_N_class0_400valsplit, choose_N_class1_400valsplit, choose_N_class2_400valsplit, choose_N_class3_400valsplit, choose_N_class4_400valsplit, choose_N_class5_400valsplit, choose_N_class6_400valsplit, choose_N_class7_400valsplit]\n",
    "for c, n in zip(classes, samples_to_choose_each_class):\n",
    "    cls_mask = (permuted_val_labels == c)\n",
    "    print('saintycheck, class {} has {} samples, to choose {}'.format(c, np.sum(cls_mask), n))\n",
    "    c_images = permuted_val_images[cls_mask]\n",
    "    c_labels = permuted_val_labels[cls_mask]\n",
    "    \n",
    "    new_400valsplit_images+=[c_images[:n]]\n",
    "    new_400valsplit_labels+=[c_labels[:n]]\n",
    "    \n",
    "new_400valsplit_set = {\"images\": np.concatenate(new_400valsplit_images, 0), \"labels\": np.concatenate(new_400valsplit_labels, 0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d9df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the new_400valsplit_set\n",
    "np.save(os.path.join(root_dir, 'nlabels400_val400', 'val.npy'), new_400valsplit_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170514f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
